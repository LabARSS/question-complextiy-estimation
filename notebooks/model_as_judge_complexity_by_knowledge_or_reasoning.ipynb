{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from mistralai import Mistral\n",
    "\n",
    "api_keys = os.environ[\"MISTRAL_API_KEYS\"]\n",
    "model = \"mistral-large-2411\"\n",
    "\n",
    "clients = [\n",
    "    Mistral(\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    for api_key in api_keys.split(\",\")\n",
    "]\n",
    "\n",
    "for client in clients:\n",
    "    # Check API is alive\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the best French cheese?\",\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=10,\n",
    "    )\n",
    "    print(chat_response.model, chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from mistralai import SDKError\n",
    "from openai import RateLimitError\n",
    "\n",
    "SLEEP_DURATION = 1.2\n",
    "if len(clients) == 2:\n",
    "    SLEEP_DURATION = 0.5\n",
    "if len(clients) >= 3:\n",
    "    SLEEP_DURATION = 0.2\n",
    "\n",
    "print(\"Sleep duration:\", SLEEP_DURATION)\n",
    "\n",
    "\n",
    "def wait(duration=SLEEP_DURATION):\n",
    "    sleep(duration)\n",
    "\n",
    "\n",
    "api_limit_hits_by_client_ids = {}\n",
    "\n",
    "\n",
    "def init_api_limits() -> None:\n",
    "    global api_limit_hits_by_client_ids\n",
    "\n",
    "    api_limit_hits_by_client_ids = {}\n",
    "    for i in range(len(clients)):\n",
    "        api_limit_hits_by_client_ids[i] = 0\n",
    "\n",
    "\n",
    "request_id = 0\n",
    "\n",
    "\n",
    "def repeat_if_hit_api_limit(f):  # (1)\n",
    "    def wrapper(*args, **kw):  # (2)\n",
    "        global api_limit_hits_by_client_ids\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                return f(*args, **kw)\n",
    "            except RateLimitError:\n",
    "                client_id = request_id % len(clients)\n",
    "                api_limit_hits_by_client_ids[client_id] += 1\n",
    "\n",
    "                total_hits = 0\n",
    "                for value in api_limit_hits_by_client_ids.values():\n",
    "                    total_hits += value\n",
    "\n",
    "                if (total_hits % 10) == 0:\n",
    "                    print(f\"API limit hit {total_hits} times. Details: {api_limit_hits_by_client_ids}\")\n",
    "                wait(2)\n",
    "            except SDKError as e:\n",
    "                if e.status_code == 429:\n",
    "                    client_id = request_id % len(clients)\n",
    "                    api_limit_hits_by_client_ids[client_id] += 1\n",
    "\n",
    "                    total_hits = 0\n",
    "                    for value in api_limit_hits_by_client_ids.values():\n",
    "                        total_hits += value\n",
    "\n",
    "                    if (total_hits % 10) == 0:\n",
    "                        print(f\"API limit hit {total_hits} times. Details: {api_limit_hits_by_client_ids}\")\n",
    "                    wait(2)\n",
    "                else:\n",
    "                    raise e\n",
    "            except Exception as e:\n",
    "                print(\"repeat_if_hit_api_limit -> unknown error\", e)\n",
    "                wait(60)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@repeat_if_hit_api_limit\n",
    "def query_model(messages):\n",
    "    global request_id\n",
    "    # print(request_id % len(clients))\n",
    "    client = clients[request_id % len(clients)]\n",
    "    request_id += 1\n",
    "    response = client.chat.complete(model=model, messages=messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath(\"\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if dir1 not in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "import importlib\n",
    "\n",
    "import utils.prompt as prompt\n",
    "\n",
    "# Required to purge the module cache and use the latest version after an update\n",
    "importlib.reload(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils.prompt as prompt\n",
    "\n",
    "# difficulty = [\"middle_school\", \"high_school\", \"undergraduate\", \"postgraduate\", \"phd\"]\n",
    "ratings = list(range(1, 11, 1))\n",
    "\n",
    "invalid_complexities = 0\n",
    "invalid_ratings = 0\n",
    "\n",
    "FIELD_REQUIRES_KNOWLEDGE = \"masj_requires_knowledge\"\n",
    "FIELD_REQUIRES_REASONING = \"masj_requires_reasoning\"\n",
    "FIELD_NUM_REASONING_STEPS = \"masj_num_reasoning_steps\"\n",
    "\n",
    "\n",
    "def estimate_reasoning_complexity_with_model(df, index, system_prompt, user_prompt):\n",
    "    global invalid_complexities\n",
    "\n",
    "    chat_response = query_model(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                [Question Start]\n",
    "                {user_prompt}\n",
    "                [Question End]\n",
    "                \"\"\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    response = chat_response.choices[0].message.content\n",
    "    try:\n",
    "        requires_knowledge = re.search(\"\\\\[\\\\[Requires knowledge:(.+?)\\\\]\\\\]\", response).group(1)\n",
    "        requires_knowledge: str = requires_knowledge.strip().lower()\n",
    "        assert requires_knowledge in prompt.valid_requires_answers\n",
    "        df.at[index, FIELD_REQUIRES_KNOWLEDGE] = requires_knowledge\n",
    "\n",
    "        requires_reasoning = re.search(\"\\\\[\\\\[Requires reasoning:(.+?)\\\\]\\\\]\", response).group(1)\n",
    "        requires_reasoning: str = requires_reasoning.strip().lower()\n",
    "        assert requires_reasoning in prompt.valid_requires_answers\n",
    "        df.at[index, FIELD_REQUIRES_REASONING] = requires_reasoning\n",
    "\n",
    "        num_reasoning_steps = re.search(\"\\\\[\\\\[Number of reasoning steps:(.+?)\\\\]\\\\]\", response).group(1)\n",
    "        num_reasoning_steps: str = num_reasoning_steps.strip().lower()\n",
    "        assert num_reasoning_steps in prompt.valid_num_reasoning_steps_answers\n",
    "        df.at[index, FIELD_NUM_REASONING_STEPS] = num_reasoning_steps\n",
    "\n",
    "        # print(f\"\"\"\n",
    "        # [Question]\n",
    "        # {user_prompt}\n",
    "        # [Response]\n",
    "        # {response}\n",
    "        # ==========\n",
    "\n",
    "        # \"\"\")\n",
    "    except:\n",
    "        print(f\"Could not extract from response:\\n{response}\\n\")\n",
    "        invalid_complexities += 1\n",
    "\n",
    "\n",
    "DUMP_EVERY = 50\n",
    "\n",
    "\n",
    "def estimate_dataset(in_filename, out_filename, get_question_from_row, get_options_from_row, original_separators=True):\n",
    "    if os.path.isfile(out_filename):\n",
    "        df = pd.read_csv(\n",
    "            out_filename,\n",
    "            sep=\"\\t\",\n",
    "            header=0,\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "            quotechar=\"\",\n",
    "            escapechar=\"\\\\\",\n",
    "        )\n",
    "    else:\n",
    "        if original_separators:\n",
    "            df = pd.read_csv(\n",
    "                in_filename,\n",
    "                sep=\"\\t\",\n",
    "                header=0,\n",
    "            )\n",
    "        else:\n",
    "            df = pd.read_csv(\n",
    "                in_filename,\n",
    "                sep=\"\\t\",\n",
    "                header=0,\n",
    "                quoting=csv.QUOTE_NONE,\n",
    "                quotechar=\"\",\n",
    "                escapechar=\"\\\\\",\n",
    "            )\n",
    "\n",
    "    global invalid_complexities\n",
    "    global invalid_ratings\n",
    "    invalid_complexities = 0\n",
    "    invalid_ratings = 0\n",
    "    init_api_limits()\n",
    "\n",
    "    if FIELD_REQUIRES_KNOWLEDGE not in df.columns:\n",
    "        df[FIELD_REQUIRES_KNOWLEDGE] = \"\"\n",
    "    if FIELD_REQUIRES_REASONING not in df.columns:\n",
    "        df[FIELD_REQUIRES_REASONING] = \"\"\n",
    "    if FIELD_NUM_REASONING_STEPS not in df.columns:\n",
    "        df[FIELD_NUM_REASONING_STEPS] = \"\"\n",
    "\n",
    "    meaningful_iteration = 0\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if (\n",
    "            isinstance(df.at[index, FIELD_REQUIRES_KNOWLEDGE], float)\n",
    "            and df.at[index, FIELD_REQUIRES_KNOWLEDGE] in prompt.valid_requires_answers\n",
    "            and df.at[index, FIELD_REQUIRES_REASONING] in prompt.valid_requires_answers\n",
    "            and df.at[index, FIELD_NUM_REASONING_STEPS] in prompt.valid_num_reasoning_steps_answers\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        meaningful_iteration += 1\n",
    "\n",
    "        complexity_user_prompt = prompt.get_user_prompt(get_question_from_row(row), get_options_from_row(row))\n",
    "        # print(complexity_user_prompt)\n",
    "\n",
    "        estimate_reasoning_complexity_with_model(\n",
    "            df, index, prompt.estimate_reasoning_complexity_system_prompt, complexity_user_prompt\n",
    "        )\n",
    "\n",
    "        if meaningful_iteration % DUMP_EVERY == 0:\n",
    "            df.to_csv(out_filename, sep=\"\\t\", quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\", index=False)\n",
    "            total_hits = 0\n",
    "            for value in api_limit_hits_by_client_ids.values():\n",
    "                total_hits += value\n",
    "            print(f\"Over {meaningful_iteration} iterations we hit {total_hits} API limits\")\n",
    "\n",
    "    df.to_csv(out_filename, sep=\"\\t\", quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\", index=False)\n",
    "    print(\n",
    "        f\"Processed dataset {out_filename}. Total entries: {df.shape[0]}. Invalid complexities: {invalid_complexities}. Invalid ratings: {invalid_ratings}\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMLU\n",
    "import ast\n",
    "\n",
    "estimate_dataset(\n",
    "    in_filename=\"../data/mmlu_final.tsv\",\n",
    "    out_filename=\"../data/mmlu_pro_stem_reasoning_score.tsv\",\n",
    "    get_question_from_row=lambda row: row[\"question\"],\n",
    "    get_options_from_row=lambda row: ast.literal_eval(row[\"options\"]),\n",
    "    original_separators=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
