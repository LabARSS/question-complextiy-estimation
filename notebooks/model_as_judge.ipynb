{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral-large-2411 Choosing the \"best\" French cheese can be\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-2411\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "# Check API is alive\n",
    "chat_response = client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the best French cheese?\",\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=10,\n",
    ")\n",
    "print(chat_response.model, chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import SDKError\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def wait():\n",
    "    sleep(1.2)\n",
    "\n",
    "\n",
    "def repeat_if_hit_api_limit(f):  # (1)\n",
    "    def wrapper(*args, **kw):  # (2)\n",
    "        while True:\n",
    "            try:\n",
    "                return f(*args, **kw)\n",
    "            except SDKError as e:\n",
    "                if e.status_code == 429:\n",
    "                    wait()\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/12032 [01:16<31:50:29,  9.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSDKError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mrepeat_if_hit_api_limit.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SDKError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[32], line 28\u001b[0m, in \u001b[0;36mmodel_as_judge\u001b[0;34m(client, model, index, system_prompt, user_prompt, answer)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@repeat_if_hit_api_limit\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_as_judge\u001b[39m(client, model, index, system_prompt, user_prompt, answer):\n\u001b[0;32m---> 28\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPlease act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user request displayed below. Your evaluation should consider factors such as the following all the settings in the system prompt, correspondences to the context of the user, the helpfulness, relevance and accuracy. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[[rating]]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, for example:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRating: [[6]]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;43m                [Instructions for Assistant]\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;43m                [Question]\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_prompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;43m                [The Start of Assistant’s Answer]\u001b[39;49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43manswer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;43m                [The End of Assistant’s Answer]\u001b[39;49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     response \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/dev/sktech/phi-4/.venv/lib/python3.12/site-packages/mistralai/chat.py:235\u001b[0m, in \u001b[0;36mChat.complete\u001b[0;34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, prediction, safe_prompt, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[1;32m    234\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mSDKError(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m, http_res\u001b[38;5;241m.\u001b[39mstatus_code, http_res_text, http_res\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5XX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mSDKError\u001b[0m: API error occurred: Status 429\n{\"message\":\"Requests rate limit exceeded\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 124\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# df = df.head(10)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m out_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_w_maj_complexity.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 124\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_question_from_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_options_from_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m processed_df\u001b[38;5;241m.\u001b[39mto_csv(out_filename, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mQUOTE_NONE, quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, escapechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 108\u001b[0m, in \u001b[0;36mestimate_dataset\u001b[0;34m(df, client, get_question_from_row, get_options_from_row, out_filename)\u001b[0m\n\u001b[1;32m    103\u001b[0m response_complexity \u001b[38;5;241m=\u001b[39m estimate_complextiy_with_model(\n\u001b[1;32m    104\u001b[0m     client, model, index, complexity_system_prompt, complexity_user_prompt\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m wait()\n\u001b[0;32m--> 108\u001b[0m \u001b[43mmodel_as_judge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplexity_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplexity_user_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_complexity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m wait()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m%\u001b[39m DUMP_EVERY \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m, in \u001b[0;36mrepeat_if_hit_api_limit.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SDKError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m         \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36mwait\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m():\n\u001b[0;32m----> 6\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "dir2 = os.path.abspath(\"\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import utils.prompt as prompt\n",
    "\n",
    "import importlib\n",
    "\n",
    "# Required to purge the module cache and use the latest version after an update\n",
    "importlib.reload(prompt)\n",
    "\n",
    "difficulty = [\"middle_school\", \"high_school\", \"undergraduate\", \"postgraduate\", \"phd\"]\n",
    "\n",
    "invalid_complexities = 0\n",
    "invalid_ratings = 0\n",
    "\n",
    "\n",
    "@repeat_if_hit_api_limit\n",
    "def model_as_judge(client, model, index, system_prompt, user_prompt, answer):\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": 'Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user request displayed below. Your evaluation should consider factors such as the following all the settings in the system prompt, correspondences to the context of the user, the helpfulness, relevance and accuracy. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example:\"Rating: [[6]]\".',\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                [Instructions for Assistant]\n",
    "                {system_prompt}\n",
    "\n",
    "                [Question]\n",
    "                {user_prompt}\n",
    "\n",
    "                [The Start of Assistant’s Answer]\n",
    "                {answer}\n",
    "                [The End of Assistant’s Answer]\n",
    "                \"\"\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    response = chat_response.choices[0].message.content\n",
    "    rating = re.search(\"\\\\[\\\\[(\\\\d+?)\\\\]\\\\]\", response).group(1)\n",
    "    # print(rating)\n",
    "\n",
    "    try:\n",
    "        rating_int = int(rating)\n",
    "        if rating_int in range(1, 11, 1):\n",
    "            df.at[index, \"masj_rating\"] = rating_int\n",
    "        else:\n",
    "            invalid_ratings += 1\n",
    "    except:\n",
    "        invalid_ratings += 1\n",
    "\n",
    "\n",
    "@repeat_if_hit_api_limit\n",
    "def estimate_complextiy_with_model(client, model, index, system_prompt, user_prompt):\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    response = chat_response.choices[0].message.content\n",
    "    complexity = re.search(\"\\\\[\\\\[(.+?)\\\\]\\\\]\", response).group(1)\n",
    "    # print(complexity)\n",
    "\n",
    "    if complexity in difficulty:\n",
    "        df.at[index, \"masj_complexity\"] = complexity\n",
    "    else:\n",
    "        invalid_complexities += 1\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "DUMP_EVERY = 100\n",
    "\n",
    "\n",
    "def estimate_dataset(df, client, get_question_from_row, get_options_from_row, out_filename):\n",
    "    df[\"masj_complexity\"] = \"\"\n",
    "    df[\"masj_rating\"] = 0\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        complexity_system_prompt = f\"You are an expert in science. Please act as an impartial judge and evaluate the complexity of the multiple-choice question below. Be as objective as possible. You must rate the question complexity by strictly following the scale: {\", \".join(difficulty)}. You must be concise and return only the complexity by strictly following this format: [[complexity]], for example: [[middle_school]].\"\n",
    "        complexity_user_prompt = prompt.get_user_prompt(get_question_from_row(row), get_options_from_row(row))\n",
    "\n",
    "        response_complexity = estimate_complextiy_with_model(\n",
    "            client, model, index, complexity_system_prompt, complexity_user_prompt\n",
    "        )\n",
    "        wait()\n",
    "\n",
    "        model_as_judge(client, model, index, complexity_system_prompt, complexity_user_prompt, response_complexity)\n",
    "        wait()\n",
    "\n",
    "        if index % DUMP_EVERY == 0:\n",
    "            df.to_csv(out_filename, sep=\"\\t\", quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\")\n",
    "\n",
    "    df.to_csv(out_filename, sep=\"\\t\", quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\")\n",
    "    print(\n",
    "        f\"Processed dataset {out_filename}. Total entries: {df.shape[0]}. Invalid complexities: {invalid_complexities}. Invalid ratings: {invalid_ratings}\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "DATASET = \"../data/mmlu_pro_stem\"\n",
    "\n",
    "df = pd.read_csv(f\"{DATASET}.tsv\", sep=\"\\t\", header=0)\n",
    "# df = df.head(10)\n",
    "\n",
    "out_filename = f\"{DATASET}_w_maj_complexity.tsv\"\n",
    "\n",
    "estimate_dataset(\n",
    "    df=df,\n",
    "    client=client,\n",
    "    get_question_from_row=lambda row: row[\"question\"],\n",
    "    get_options_from_row=lambda row: ast.literal_eval(row[\"options\"]),\n",
    "    out_filename=out_filename,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
