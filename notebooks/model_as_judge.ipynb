{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral-large-2411 Choosing the \"best\" French cheese can be\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-2411\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "# Check API is alive\n",
    "chat_response = client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the best French cheese?\",\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=10,\n",
    ")\n",
    "print(chat_response.model, chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undergraduate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:13,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:12,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:11,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:08,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:09<00:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:10<00:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:13<00:03,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undergraduate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:15<00:01,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "dir2 = os.path.abspath(\"\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from mistralai import SDKError\n",
    "import re\n",
    "\n",
    "import utils.prompt as prompt\n",
    "\n",
    "import importlib\n",
    "\n",
    "# Required to purge the module cache and use the latest version after an update\n",
    "importlib.reload(prompt)\n",
    "\n",
    "difficulty = [\"middle_school\", \"high_school\", \"undergraduate\", \"postgraduate\", \"phd\"]\n",
    "\n",
    "extract_regex = re.compile(\"\\\\[\\\\[(.*?)\\\\]\\\\]\")\n",
    "\n",
    "invalid_complexities = 0\n",
    "\n",
    "\n",
    "def estimate_dataset(df, client, get_question_from_row, get_options_from_row):\n",
    "    df[\"masj_complexity\"] = \"\"\n",
    "    df[\"masj_mt_rating\"] = 0\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        while True:\n",
    "            try:\n",
    "                chat_response = client.chat.complete(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": f\"You are an expert in science. Please act as an impartial judge and evaluate the complexity of the multiple-choice question below. Be as objective as possible. You must rate the question complexity by strictly following the scale: {\", \".join(difficulty)}. You must be concise and return only the complexity by strictly following this format: [[complexity]], for example: [[middle_school]].\",\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt.get_user_prompt(get_question_from_row(row), get_options_from_row(row)),\n",
    "                        },\n",
    "                    ],\n",
    "                )\n",
    "                response = chat_response.choices[0].message.content\n",
    "                complexity = extract_regex.search(response).group(1)\n",
    "                # print(complexity)\n",
    "\n",
    "                if complexity in difficulty:\n",
    "                    df.at[index, \"masj_complexity\"] = complexity\n",
    "                else:\n",
    "                    invalid_complexities += 1\n",
    "\n",
    "                sleep(1.2)\n",
    "\n",
    "                break\n",
    "            except SDKError as e:\n",
    "                if e.status_code == 429:\n",
    "                    sleep(1)\n",
    "                else:\n",
    "                    raise e\n",
    "    return df\n",
    "\n",
    "\n",
    "DATASET = \"../data/mmlu_pro_stem\"\n",
    "\n",
    "df = pd.read_csv(f\"{DATASET}.tsv\", sep=\"\\t\", header=0)\n",
    "df = df.head(10)\n",
    "\n",
    "processed_df = estimate_dataset(\n",
    "    df=df,\n",
    "    client=client,\n",
    "    get_question_from_row=lambda row: row[\"question\"],\n",
    "    get_options_from_row=lambda row: ast.literal_eval(row[\"options\"]),\n",
    ")\n",
    "# processed_df.to_csv(f\"{DATASET}_w_maj_complexity.tsv\", sep=\"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
