{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral-large-2411 Determining the \"best\" French cheese can\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-2411\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "# Check API is alive\n",
    "chat_response = client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the best French cheese?\",\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=10,\n",
    ")\n",
    "print(chat_response.model, chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import SDKError\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def wait():\n",
    "    sleep(1.2)\n",
    "\n",
    "\n",
    "def repeat_if_hit_api_limit(f):  # (1)\n",
    "    def wrapper(*args, **kw):  # (2)\n",
    "        while True:\n",
    "            try:\n",
    "                return f(*args, **kw)\n",
    "            except SDKError as e:\n",
    "                if e.status_code == 429:\n",
    "                    wait()\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/12032 [05:29<27:24:45,  8.23s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 129\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# df = df.head(10)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m out_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_w_maj_complexity.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 129\u001b[0m \u001b[43mestimate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_question_from_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_options_from_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 109\u001b[0m, in \u001b[0;36mestimate_dataset\u001b[0;34m(df, client, get_question_from_row, get_options_from_row, out_filename)\u001b[0m\n\u001b[1;32m    104\u001b[0m response_complexity \u001b[38;5;241m=\u001b[39m estimate_complextiy_with_model(\n\u001b[1;32m    105\u001b[0m     client, model, index, complexity_system_prompt, complexity_user_prompt\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    107\u001b[0m wait()\n\u001b[0;32m--> 109\u001b[0m \u001b[43mmodel_as_judge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplexity_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplexity_user_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_complexity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m wait()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m%\u001b[39m DUMP_EVERY \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mrepeat_if_hit_api_limit.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SDKError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mmodel_as_judge\u001b[0;34m(client, model, index, system_prompt, user_prompt, answer)\u001b[0m\n\u001b[1;32m     29\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcomplete(\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     31\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     ],\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m response \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m---> 53\u001b[0m rating \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m[\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m[(\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43md+?)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# print(rating)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "dir2 = os.path.abspath(\"\")\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import utils.prompt as prompt\n",
    "\n",
    "import importlib\n",
    "\n",
    "# Required to purge the module cache and use the latest version after an update\n",
    "importlib.reload(prompt)\n",
    "\n",
    "difficulty = [\"middle_school\", \"high_school\", \"undergraduate\", \"postgraduate\", \"phd\"]\n",
    "\n",
    "invalid_complexities = 0\n",
    "invalid_ratings = 0\n",
    "\n",
    "\n",
    "@repeat_if_hit_api_limit\n",
    "def model_as_judge(client, model, index, system_prompt, user_prompt, answer):\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": 'Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user request displayed below. Your evaluation should consider factors such as the following all the settings in the system prompt, correspondences to the context of the user, the helpfulness, relevance and accuracy. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example:\"Rating: [[6]]\".',\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                [Instructions for Assistant]\n",
    "                {system_prompt}\n",
    "\n",
    "                [Question]\n",
    "                {user_prompt}\n",
    "\n",
    "                [The Start of Assistant’s Answer]\n",
    "                {answer}\n",
    "                [The End of Assistant’s Answer]\n",
    "                \"\"\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    response = chat_response.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        rating = re.search(\"\\\\[\\\\[(\\\\d+?)\\\\]\\\\]\", response).group(1)\n",
    "        # print(rating)\n",
    "        rating_int = int(rating)\n",
    "        if rating_int in range(1, 11, 1):\n",
    "            df.at[index, \"masj_rating\"] = rating_int\n",
    "        else:\n",
    "            invalid_ratings += 1\n",
    "    except:\n",
    "        print(f\"Could not extract rating from response:\\n{response}\\n\")\n",
    "        invalid_ratings += 1\n",
    "\n",
    "\n",
    "@repeat_if_hit_api_limit\n",
    "def estimate_complextiy_with_model(client, model, index, system_prompt, user_prompt):\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    response = chat_response.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        complexity = re.search(\"\\\\[\\\\[(.+?)\\\\]\\\\]\", response).group(1)\n",
    "        # print(complexity)\n",
    "\n",
    "        if complexity in difficulty:\n",
    "            df.at[index, \"masj_complexity\"] = complexity\n",
    "        else:\n",
    "            invalid_complexities += 1\n",
    "    except:\n",
    "        print(f\"Could not extract complexity from response:\\n{response}\\n\")\n",
    "        invalid_complexities += 1\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "DUMP_EVERY = 100\n",
    "\n",
    "\n",
    "def estimate_dataset(df, client, get_question_from_row, get_options_from_row, out_filename):\n",
    "    df[\"masj_complexity\"] = \"\"\n",
    "    df[\"masj_rating\"] = 0\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        complexity_system_prompt = f\"You are an expert in science. Please act as an impartial judge and evaluate the complexity of the multiple-choice question below. Be as objective as possible. You must rate the question complexity by strictly following the scale: {\", \".join(difficulty)}. You must be concise and return only the complexity by strictly following this format: [[complexity]], for example: [[middle_school]].\"\n",
    "        complexity_user_prompt = prompt.get_user_prompt(get_question_from_row(row), get_options_from_row(row))\n",
    "\n",
    "        response_complexity = estimate_complextiy_with_model(\n",
    "            client, model, index, complexity_system_prompt, complexity_user_prompt\n",
    "        )\n",
    "        wait()\n",
    "\n",
    "        model_as_judge(client, model, index, complexity_system_prompt, complexity_user_prompt, response_complexity)\n",
    "        wait()\n",
    "\n",
    "        if index % DUMP_EVERY == 0:\n",
    "            df.to_csv(out_filename, sep=\"\\t\", quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\", index=False)\n",
    "\n",
    "    df.to_csv(out_filename, sep=\"\\t\", quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\", index=False)\n",
    "    print(\n",
    "        f\"Processed dataset {out_filename}. Total entries: {df.shape[0]}. Invalid complexities: {invalid_complexities}. Invalid ratings: {invalid_ratings}\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "DATASET = \"../data/mmlu_pro_stem\"\n",
    "\n",
    "df = pd.read_csv(f\"{DATASET}.tsv\", sep=\"\\t\", header=0)\n",
    "# df = df.head(10)\n",
    "\n",
    "out_filename = f\"{DATASET}_w_maj_complexity.tsv\"\n",
    "\n",
    "estimate_dataset(\n",
    "    df=df,\n",
    "    client=client,\n",
    "    get_question_from_row=lambda row: row[\"question\"],\n",
    "    get_options_from_row=lambda row: ast.literal_eval(row[\"options\"]),\n",
    "    out_filename=out_filename,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
