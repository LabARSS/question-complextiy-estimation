{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d9d8e7-4c5e-4d2a-bcac-57d437449da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  3 12:35:33 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:57:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              77W / 400W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf68720-77f8-444f-9ec2-7f4de0b26a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1074585-aefd-436e-9965-e542c0a767f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 1\n",
    "VALID_PART = 0.2\n",
    "MAX_NEW_TOKENS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "WARMUP_STEPS_COEFF = 0.1\n",
    "DATA_PATH = Path(\"data\")\n",
    "MODEL_NAME = \"microsoft/phi-4\"\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SYSTEM_PROMPT = \"You are an expert in science. Answer the questions. Write only the answer number and nothing else.\"\n",
    "PROMPT = \"Choose one of the answers. Write down ONLY the NUMBER of the correct answer and nothing else.\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99e88dda-a7a5-4b0f-948b-06416962cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9625 2407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>answer</th>\n",
       "      <th>options</th>\n",
       "      <th>category</th>\n",
       "      <th>question</th>\n",
       "      <th>cot_content</th>\n",
       "      <th>question_id</th>\n",
       "      <th>output_text</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>meta_cluster</th>\n",
       "      <th>base_cluster</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stemez-Biology</td>\n",
       "      <td>I</td>\n",
       "      <td>[The gland in the thorax is the only gland inv...</td>\n",
       "      <td>biology</td>\n",
       "      <td>The hormone which brings about metamorphosis o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3031</td>\n",
       "      <td>9</td>\n",
       "      <td>262</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Genetics &amp; Biology</td>\n",
       "      <td>The hormone which brings about metamorphosis o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theoremQA-Physics</td>\n",
       "      <td>C</td>\n",
       "      <td>[2.50, 3.98, 3.26, 2.75, 5.00, 6.15, 1.92, 4.5...</td>\n",
       "      <td>physics</td>\n",
       "      <td>You wish to put a 1000-kg satellite into a cir...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9127</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>Scientific Calculations</td>\n",
       "      <td>Physics Calculation Questions</td>\n",
       "      <td>You wish to put a 1000-kg satellite into a cir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ori_mmlu-professional_psychology</td>\n",
       "      <td>F</td>\n",
       "      <td>[high ability and high motivation., low abilit...</td>\n",
       "      <td>psychology</td>\n",
       "      <td>\"According to Hersey and Blanchard’s situation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2070</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>Psychology Behavior</td>\n",
       "      <td>Psychology Questions (0)</td>\n",
       "      <td>\"According to Hersey and Blanchard’s situation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ori_mmlu-econometrics</td>\n",
       "      <td>I</td>\n",
       "      <td>[Exactly 1, More than 2, Between 1 and 2, Less...</td>\n",
       "      <td>economics</td>\n",
       "      <td>Consider the estimation of a GARCH-M model. If...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7180</td>\n",
       "      <td>9</td>\n",
       "      <td>101</td>\n",
       "      <td>Statistical Analysis</td>\n",
       "      <td>Econometrics Tests and Models</td>\n",
       "      <td>Consider the estimation of a GARCH-M model. If...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stemez-ElectricCircuits</td>\n",
       "      <td>B</td>\n",
       "      <td>[f(t) = [e^-2t + 2.24e^-2tsin(5t - 26.6°)] u(t...</td>\n",
       "      <td>engineering</td>\n",
       "      <td>Evaluate f(t) if F(s) = [(3s^2 + 17s + 47) / {...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11617</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>Engineering Calculations</td>\n",
       "      <td>Electric Circuit Calculations</td>\n",
       "      <td>Evaluate f(t) if F(s) = [(3s^2 + 17s + 47) / {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9620</th>\n",
       "      <td>ori_mmlu-philosophy</td>\n",
       "      <td>A</td>\n",
       "      <td>[do that which is good and not to approve of i...</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>According to Butler, it is impossible to:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11063</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>Legal &amp; Moral Implications</td>\n",
       "      <td>Moral Disputes</td>\n",
       "      <td>According to Butler, it is impossible to:\\n\\n1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621</th>\n",
       "      <td>ori_mmlu-professional_law</td>\n",
       "      <td>C</td>\n",
       "      <td>[Albert did not intentionally make the mistake...</td>\n",
       "      <td>law</td>\n",
       "      <td>Albert Attorney was a solo practitioner in Lit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1702</td>\n",
       "      <td>3</td>\n",
       "      <td>309</td>\n",
       "      <td>Legal &amp; Moral Implications</td>\n",
       "      <td>Legal Contracts &amp; Property</td>\n",
       "      <td>Albert Attorney was a solo practitioner in Lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>ori_mmlu-high_school_macroeconomics</td>\n",
       "      <td>D</td>\n",
       "      <td>[increase the consumer price index and the GDP...</td>\n",
       "      <td>economics</td>\n",
       "      <td>An increase in the price of forklifts imported...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7557</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>Economics &amp; Finance MCQs</td>\n",
       "      <td>Economic Concepts &amp; Policies</td>\n",
       "      <td>An increase in the price of forklifts imported...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>ori_mmlu-computer_security</td>\n",
       "      <td>C</td>\n",
       "      <td>[Given H(k \\| m)H(k∥m) anyone can compute H(w ...</td>\n",
       "      <td>computer science</td>\n",
       "      <td>Let HH be a Merkle-Damgard hash function is H:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10637</td>\n",
       "      <td>3</td>\n",
       "      <td>217</td>\n",
       "      <td>CS Subfield Queries</td>\n",
       "      <td>Computer Science Questions</td>\n",
       "      <td>Let HH be a Merkle-Damgard hash function is H:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9624</th>\n",
       "      <td>stemez-Electromagnetics</td>\n",
       "      <td>C</td>\n",
       "      <td>[C = [(πL) / {ε₀ * ln(b/a)}], C = [(πε₀L) / {l...</td>\n",
       "      <td>engineering</td>\n",
       "      <td>Use Laplace's equation in cylindrical coordina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11323</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>Engineering Calculations</td>\n",
       "      <td>Electric Circuit Calculations</td>\n",
       "      <td>Use Laplace's equation in cylindrical coordina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9625 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      src answer  \\\n",
       "0                          stemez-Biology      I   \n",
       "1                       theoremQA-Physics      C   \n",
       "2        ori_mmlu-professional_psychology      F   \n",
       "3                   ori_mmlu-econometrics      I   \n",
       "4                 stemez-ElectricCircuits      B   \n",
       "...                                   ...    ...   \n",
       "9620                  ori_mmlu-philosophy      A   \n",
       "9621            ori_mmlu-professional_law      C   \n",
       "9622  ori_mmlu-high_school_macroeconomics      D   \n",
       "9623           ori_mmlu-computer_security      C   \n",
       "9624              stemez-Electromagnetics      C   \n",
       "\n",
       "                                                options          category  \\\n",
       "0     [The gland in the thorax is the only gland inv...           biology   \n",
       "1     [2.50, 3.98, 3.26, 2.75, 5.00, 6.15, 1.92, 4.5...           physics   \n",
       "2     [high ability and high motivation., low abilit...        psychology   \n",
       "3     [Exactly 1, More than 2, Between 1 and 2, Less...         economics   \n",
       "4     [f(t) = [e^-2t + 2.24e^-2tsin(5t - 26.6°)] u(t...       engineering   \n",
       "...                                                 ...               ...   \n",
       "9620  [do that which is good and not to approve of i...        philosophy   \n",
       "9621  [Albert did not intentionally make the mistake...               law   \n",
       "9622  [increase the consumer price index and the GDP...         economics   \n",
       "9623  [Given H(k \\| m)H(k∥m) anyone can compute H(w ...  computer science   \n",
       "9624  [C = [(πL) / {ε₀ * ln(b/a)}], C = [(πε₀L) / {l...       engineering   \n",
       "\n",
       "                                               question  cot_content  \\\n",
       "0     The hormone which brings about metamorphosis o...          NaN   \n",
       "1     You wish to put a 1000-kg satellite into a cir...          NaN   \n",
       "2     \"According to Hersey and Blanchard’s situation...          NaN   \n",
       "3     Consider the estimation of a GARCH-M model. If...          NaN   \n",
       "4     Evaluate f(t) if F(s) = [(3s^2 + 17s + 47) / {...          NaN   \n",
       "...                                                 ...          ...   \n",
       "9620          According to Butler, it is impossible to:          NaN   \n",
       "9621  Albert Attorney was a solo practitioner in Lit...          NaN   \n",
       "9622  An increase in the price of forklifts imported...          NaN   \n",
       "9623  Let HH be a Merkle-Damgard hash function is H:...          NaN   \n",
       "9624  Use Laplace's equation in cylindrical coordina...          NaN   \n",
       "\n",
       "      question_id output_text  total_tokens                meta_cluster  \\\n",
       "0            3031           9           262               Miscellaneous   \n",
       "1            9127           3           125     Scientific Calculations   \n",
       "2            2070           6            80         Psychology Behavior   \n",
       "3            7180           9           101        Statistical Analysis   \n",
       "4           11617           2           179    Engineering Calculations   \n",
       "...           ...         ...           ...                         ...   \n",
       "9620        11063           1           113  Legal & Moral Implications   \n",
       "9621         1702           3           309  Legal & Moral Implications   \n",
       "9622         7557           4            79    Economics & Finance MCQs   \n",
       "9623        10637           3           217         CS Subfield Queries   \n",
       "9624        11323           3           175    Engineering Calculations   \n",
       "\n",
       "                       base_cluster  \\\n",
       "0                Genetics & Biology   \n",
       "1     Physics Calculation Questions   \n",
       "2          Psychology Questions (0)   \n",
       "3     Econometrics Tests and Models   \n",
       "4     Electric Circuit Calculations   \n",
       "...                             ...   \n",
       "9620                 Moral Disputes   \n",
       "9621     Legal Contracts & Property   \n",
       "9622   Economic Concepts & Policies   \n",
       "9623     Computer Science Questions   \n",
       "9624  Electric Circuit Calculations   \n",
       "\n",
       "                                             input_text  \n",
       "0     The hormone which brings about metamorphosis o...  \n",
       "1     You wish to put a 1000-kg satellite into a cir...  \n",
       "2     \"According to Hersey and Blanchard’s situation...  \n",
       "3     Consider the estimation of a GARCH-M model. If...  \n",
       "4     Evaluate f(t) if F(s) = [(3s^2 + 17s + 47) / {...  \n",
       "...                                                 ...  \n",
       "9620  According to Butler, it is impossible to:\\n\\n1...  \n",
       "9621  Albert Attorney was a solo practitioner in Lit...  \n",
       "9622  An increase in the price of forklifts imported...  \n",
       "9623  Let HH be a Merkle-Damgard hash function is H:...  \n",
       "9624  Use Laplace's equation in cylindrical coordina...  \n",
       "\n",
       "[9625 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"mmlu_pro_stem.tsv\"\n",
    "tag = \"_\".join(\n",
    "    [\n",
    "        \"scheduler\", \n",
    "        data_name.split(\".\")[0],\n",
    "        str(EPOCHS),\n",
    "        str(BATCH_SIZE),\n",
    "        str(LEARNING_RATE),\n",
    "        str(GRADIENT_ACCUMULATION_STEPS),\n",
    "        str(WARMUP_STEPS_COEFF)\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_path = os.path.join(DATA_PATH, data_name)\n",
    "\n",
    "df_mmlu = pd.read_csv(data_path, sep=\"\\t\")\n",
    "df_mmlu = shuffle(df_mmlu)\n",
    "df_mmlu[\"options\"] = df_mmlu[\"options\"].apply(ast.literal_eval)\n",
    "df_mmlu[\"answer_index\"] = df_mmlu[\"answer_index\"].apply(lambda x: str(x + 1))\n",
    "\n",
    "def enumerate_question_and_options(line):\n",
    "    enumerated_variants = \"\\n\".join(\n",
    "        f\"{i + 1}) {option}\" for i, option in enumerate(line[\"options\"])\n",
    "    )\n",
    "    return f\"{line['question']}\\n\\n{enumerated_variants}\"\n",
    "\n",
    "df_mmlu[\"input_text\"] = df_mmlu.apply(enumerate_question_and_options, axis=1)\n",
    "df_mmlu = df_mmlu.rename(columns={\"answer_index\": \"output_text\"})\n",
    "\n",
    "train_length = int((1 - VALID_PART) * df_mmlu.shape[0])\n",
    "df_train = df_mmlu.iloc[:train_length].reset_index(drop=True)\n",
    "df_valid = df_mmlu.iloc[train_length:].reset_index(drop=True)\n",
    "\n",
    "print(df_train.shape[0], df_valid.shape[0])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ddf0eb-de09-4f75-bc8b-b966f58c88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {\n",
    "            \"input_text\": row[\"input_text\"],\n",
    "            \"output_text\": row[\"output_text\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b792ee71-6ad8-492c-b599-6a477fb4eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LLMDataset(df_train)\n",
    "valid_dataset = LLMDataset(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93b2600-f366-4038-aa26-26a875e38e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_fn(b, tokenizer)\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda b: collate_fn(b, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7b3fbf-0672-4841-a837-f7ffb11ec7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, tokenizer):\n",
    "\n",
    "    input_prompts = []\n",
    "    output_texts = []\n",
    "    \n",
    "    for item in batch:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": PROMPT + \"\\n\\n\" + item[\"input_text\"]},\n",
    "        ]\n",
    "\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        input_prompts.append(formatted_prompt)\n",
    "        output_texts.append(item[\"output_text\"])\n",
    "\n",
    "    joined_texts = [\n",
    "        ip + ot for ip, ot in zip(input_prompts, output_texts)\n",
    "    ]\n",
    "    \n",
    "    tokens = tokenizer(\n",
    "        joined_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    input_ids = tokens[\"input_ids\"]\n",
    "    attention_mask = tokens[\"attention_mask\"]\n",
    "\n",
    "    labels = input_ids.clone()\n",
    "    \n",
    "    prompt_lens = []\n",
    "    for ip in input_prompts:\n",
    "        tok_prompt = tokenizer(ip, add_special_tokens=False)\n",
    "        prompt_lens.append(len(tok_prompt[\"input_ids\"]))\n",
    "    \n",
    "    for i, p_len in enumerate(prompt_lens):\n",
    "        labels[i, :p_len] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cefc569c-620d-499d-b0bc-956ec7f6ccbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e914b5fe6bbd4327abfb53853b884b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0950e8-7ad6-47d2-a040-b59029bc7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for layer in model.model.layers[36:]:\n",
    "    for param in layer.self_attn.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52b26a5-1d93-462e-925f-6aa66bddc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validating\", leave=False):\n",
    "\n",
    "            for i in range(batch[\"input_ids\"].shape[0]):\n",
    "                input_ids_sample = batch[\"input_ids\"][i].unsqueeze(0).to(DEVICE)\n",
    "                label_ids_sample = batch[\"labels\"][i]\n",
    "                \n",
    "                ref_text_indices = label_ids_sample[label_ids_sample != -100]\n",
    "                ref_text = tokenizer.decode(ref_text_indices, skip_special_tokens=True)\n",
    "\n",
    "                prompt_indices = batch[\"input_ids\"][i][batch[\"labels\"][i] == -100]\n",
    "                prompt_text = tokenizer.decode(prompt_indices, skip_special_tokens=True)\n",
    "\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt_text},\n",
    "                ]\n",
    "                formatted_prompt = tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True\n",
    "                )\n",
    "                \n",
    "                inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "                \n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=MAX_NEW_TOKENS,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                \n",
    "                input_length = inputs.input_ids.shape[1]\n",
    "                generated_text = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "                \n",
    "                total += 1\n",
    "                if generated_text.strip() == ref_text.strip():\n",
    "                    correct += 1\n",
    "                # print(\"Ref: \", ref_text.strip())\n",
    "                # print(\"Gen: \", generated_text.strip())\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "212729cd-f88d-477e-947b-58967d8e2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, optimizer, scheduler, gradient_accumulation_steps):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for i, batch in enumerate(tqdm(train_dataloader, desc=\"Training\", leave=False)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        raw_loss = outputs.loss\n",
    "        loss = raw_loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        epoch_loss += raw_loss.item()\n",
    "\n",
    "        # Perform an optimizer step after accumulating the gradients\n",
    "        if (i + 1) % gradient_accumulation_steps == 0 or (i + 1) == len(train_dataloader):\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return epoch_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fbda96a-2397-4ec5-a602-53c6351da04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "\n",
    "total_training_steps = (\n",
    "    ((len(train_dataloader) + GRADIENT_ACCUMULATION_STEPS - 1) // GRADIENT_ACCUMULATION_STEPS)\n",
    "    * EPOCHS\n",
    ")\n",
    "warmup_steps = int(total_training_steps * WARMUP_STEPS_COEFF)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f7667-89f2-4416-a8fb-58c9cafd4823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1/5 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1891ce13adf64571aa8ed3ebb834c7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/2407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_history = []\n",
    "valid_acc_history = []\n",
    "\n",
    "best_acc = - float(\"inf\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"=== Epoch {epoch+1}/{EPOCHS} ===\")\n",
    "\n",
    "    val_acc = validate(model, valid_dataloader, tokenizer)\n",
    "    valid_acc_history.append(val_acc)\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        model.save_pretrained(\"weights_and_histories\")\n",
    "    \n",
    "    avg_train_loss = train_one_epoch(model, train_dataloader, optimizer, scheduler, GRADIENT_ACCUMULATION_STEPS)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    df_history = pd.DataFrame(\n",
    "        {\n",
    "            \"epoch\": list(range(epoch + 1)),\n",
    "            \"train_loss\": train_loss_history,\n",
    "            \"valid_acc\": valid_acc_history,\n",
    "        }\n",
    "    )\n",
    "    df_history.to_excel(os.path.join(\"weights_and_histories\", f\"{tag}.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eaaee5-4da8-45be-9a21-d11c69348b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c802e24-278d-400b-9437-58c7b3b12b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
